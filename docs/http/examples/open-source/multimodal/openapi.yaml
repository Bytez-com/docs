openapi: 3.0.3
info:
  title: Open Source AI Models API – Multimodal
  description: API for running open-source AI models that take text, vision, audio, and video as input.
  version: 1.0.0

servers:
  - url: https://api.bytez.com
    description: Production server

paths:
  /models/v2/microsoft/Phi-3-mini-4k-instruct:
    post:
      summary: Chat model for text generation
      description: Generate text with the Phi-3-mini-4k-instruct model.
      operationId: textGeneration
      requestBody:
        $ref: '#/components/requestBodies/UniversalRequestBody'
      responses:
        '200':
          description: Successful text-generation response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GenericSuccessResponseSchema'
      security:
        - apiKeyAuth: []

  /models/v2/meta-llama/Llama-3.2-11B-Vision-Instruct:
    post:
      summary: Chat model for vision-based input
      description: Analyze images with Llama-3.2-11B-Vision-Instruct.
      operationId: visionAnalysis
      requestBody:
        $ref: '#/components/requestBodies/UniversalRequestBody'
      responses:
        '200':
          description: Successful vision-analysis response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GenericSuccessResponseSchema'
      security:
        - apiKeyAuth: []

  /models/v2/Qwen/Qwen2-Audio-7B-Instruct:
    post:
      summary: Chat model for audio-based input
      description: Analyze audio with Qwen2-Audio-7B-Instruct.
      operationId: audioAnalysis
      requestBody:
        $ref: '#/components/requestBodies/UniversalRequestBody'
      responses:
        '200':
          description: Successful audio-analysis response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GenericSuccessResponseSchema'
      security:
        - apiKeyAuth: []

  /models/v2/llava-hf/LLaVA-NeXT-Video-7B-hf:
    post:
      summary: Chat model for video-based input
      description: Analyze video with LLaVA-NeXT-Video-7B-hf.
      operationId: videoAnalysis
      requestBody:
        $ref: '#/components/requestBodies/UniversalRequestBody'
      responses:
        '200':
          description: Successful video-analysis response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GenericSuccessResponseSchema'
      security:
        - apiKeyAuth: []

# ───────────────────────────── Components ─────────────────────────────
components:
  # ---------- Schemas ----------
  schemas:
    UniversalRequestBodySchema:
      type: object
      properties:
        text: { type: string, description: Input text for NLP tasks. }
        messages:
          type: array
          description: Conversation history.
          items:
            type: object
            required: [role, content]
            properties:
              role: { type: string, enum: [system, user, assistant] }
              content:
                oneOf:
                  - type: string
                  - type: array
                    items:
                      type: object
                      required: [type]
                      properties:
                        type: { type: string, enum: [text, image, audio, video] }
                        text: { type: string }
                        url: { type: string, format: uri }
                        base64: { type: string }
        url: { type: string, format: uri, description: URL to image/audio/video. }
        base64: { type: string, description: Base64-encoded image/audio/video. }
        question: { type: string, description: Question text (QA tasks). }
        context: { type: string, description: Context paragraph (QA tasks). }
        candidate_labels:
          type: array
          items: { type: string }
          description: Candidate labels (zero-shot).
        stream: { type: boolean, description: Enable text streaming. }
        json: { type: boolean, description: Stream media instead of JSON. }
        params:
          type: object
          description: Model-specific parameters.
          properties:
            min_length: { type: integer }
            max_length: { type: integer }
            temperature: { type: number }

    GenericSuccessResponseSchema:
      type: object
      required: [error, output]
      properties:
        error:
          type: string
          nullable: true
          description: Null on success; otherwise an error message.
        output:
          description: Model-specific output (string, object, or array).

  # ---------- Request Bodies ----------
  requestBodies:
    UniversalRequestBody:
      description: Universal schema supporting text, chat, image, audio, video, QA, zero-shot, etc.
      required: true
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/UniversalRequestBodySchema'

  # ---------- Security ----------
  securitySchemes:
    apiKeyAuth:
      type: apiKey
      in: header
      name: Authorization
      description: >
        Set `Authorization` header to `Key BYTEZ_KEY` (e.g. 'Authorization': 'Key ABC123')
